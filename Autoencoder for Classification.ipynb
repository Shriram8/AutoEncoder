{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A7 Autoencoder for Classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have talked in lecture about how an Autoencoder nonlinearly reduces the dimensionality of data.  In this assignment you will \n",
    "1. load an autoencoder network already trained in the MNIST data,\n",
    "2. apply it to the MNIST training set to obtain the outputs of the units in the bottleneck layer as a new representation of each training set image with a greatly reduced dimensionality,\n",
    "3. Train a fully-connected classification network on this new representation.\n",
    "4. Report on the percent of training and testing images correctly classified.  Compare with the accuracy you get with the original images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download [nn_torch.zip](https://www.cs.colostate.edu/~anderson/cs445/notebooks/nn_torch.zip) and extract the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import pickle\n",
    "import gzip\n",
    "import torch\n",
    "import neuralnetworks_torch as nntorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's load the MNIST data. You may download it here: [mnist.pkl.gz](http://deeplearning.net/data/mnist/mnist.pkl.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 784), (50000,), (10000, 784), (10000,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gzip.open('mnist.pkl.gz', 'rb') as f:\n",
    "    train_set, valid_set, test_set = pickle.load(f, encoding='latin1')\n",
    "\n",
    "Xtrain = train_set[0]\n",
    "Ttrain = train_set[1]\n",
    "\n",
    "Xtest = test_set[0]\n",
    "Ttest = test_set[1]\n",
    "\n",
    "Xtrain.shape, Ttrain.shape, Xtest.shape, Ttest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load the network saved in Lecture Notes 21, run the following code.  This loads the saved torch neural network that was trained in a GPU.  It loads the state of that net (its weights) into a new net of the same structure but allocated on the CPU.\n",
    "\n",
    "First download [mnist_autoencoder.pt](https://www.cs.colostate.edu/~anderson/cs445/notebooks/mnist_autoencoder.pt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_in = Xtrain.shape[1]\n",
    "n_hiddens_per_layer = [500, 100, 50, 50, 20, 50, 50, 100, 500]\n",
    "nnet_autoencoder = nntorch.NeuralNetwork(n_in, n_hiddens_per_layer, n_in, device='cpu')\n",
    "\n",
    "nnet_autoencoder.load_state_dict(torch.load('mnist_autoencoder.pt', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the output of the units in the middle hidden layer, run `use_to_middle` function implemented for you in `neuralnetworks_torch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 20)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain_reduced = nnet_autoencoder.use_to_middle(Xtrain)\n",
    "Xtrain_reduced.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And while we are here, let's get the reduced representation of `Xtest` also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 20)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest_reduced = nnet_autoencoder.use_to_middle(Xtest)\n",
    "Xtest_reduced.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement\n",
    "\n",
    "Your jobs are now to\n",
    "1. train one fully-connected classifier using `Xtrain_reduced` and `Ttrain` and test it with `Xtest_reduced` and `Ttest`, and\n",
    "2. train a second fully-connected classifier using `Xtrain` and `Ttrain` and test it with `Xtest` and `Ttest.\n",
    "\n",
    "Try to find parameters (hidden network structure, number of epochs, and learning rate) for which the classifier given the reduced representation does almost as well as the other classifier with the orignal data. Discuss your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example for part of Step 1.  It shows a brief training session (small number of epochs and simple hidden layer structure) for using the reduced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 20)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " Xtrain_reduced.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1 with Original Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200: RMSE 0.108\n",
      "Epoch 400: RMSE 0.021\n",
      "Epoch 600: RMSE 0.005\n",
      "Epoch 800: RMSE 0.002\n",
      "Epoch 1000: RMSE 0.001\n",
      "Epoch 1200: RMSE 0.001\n",
      "Epoch 1400: RMSE 0.000\n",
      "Epoch 1600: RMSE 0.000\n",
      "Epoch 1800: RMSE 0.000\n",
      "Epoch 2000: RMSE 0.000\n",
      "% Correct  Train 100.00\n",
      "% Correct  Test 97.88\n"
     ]
    }
   ],
   "source": [
    "n_in = Xtrain.shape[1]\n",
    "reduced_classifier = nntorch.NeuralNetwork_Classifier(n_in, [200,200], 10, device='cpu')\n",
    "\n",
    "n_epochs = 2000\n",
    "reduced_classifier.train(Xtrain, Ttrain, n_epochs, 0.001, method='adam', standardize='')\n",
    "\n",
    "Classes1, _ = reduced_classifier.use(Xtrain)\n",
    "\n",
    "def percent_correct(Predicted, Target):\n",
    "    return 100 * np.mean(Predicted == Target)\n",
    "\n",
    "print(f'% Correct  Train {percent_correct(Classes1, Ttrain):.2f}')\n",
    "\n",
    "Classes2, _ = reduced_classifier.use(Xtest)\n",
    "print(f'% Correct  Test {percent_correct(Classes2, Ttest):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment4 with reduced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 600: RMSE 0.344\n",
      "Epoch 1200: RMSE 0.283\n",
      "Epoch 1800: RMSE 0.225\n",
      "Epoch 2400: RMSE 0.150\n",
      "Epoch 3000: RMSE 0.100\n",
      "Epoch 3600: RMSE 0.070\n",
      "Epoch 4200: RMSE 0.047\n",
      "Epoch 4800: RMSE 0.030\n",
      "Epoch 5400: RMSE 0.017\n",
      "Epoch 6000: RMSE 0.009\n",
      "% Correct  Train 99.92\n",
      "% Correct  Test 98.18\n"
     ]
    }
   ],
   "source": [
    "n_in = Xtrain_reduced.shape[1]\n",
    "reduced_classifier = nntorch.NeuralNetwork_Classifier(n_in, [200,200,200], 10, device='cpu')\n",
    "\n",
    "n_epochs = 6000\n",
    "reduced_classifier.train(Xtrain_reduced, Ttrain, n_epochs, 0.0001, method='adam', standardize='')\n",
    "\n",
    "\n",
    "\n",
    "def percent_correct(Predicted, Target):\n",
    "    return 100 * np.mean(Predicted == Target)\n",
    "\n",
    "Classesred1, _ = reduced_classifier.use(Xtrain_reduced)\n",
    "print(f'% Correct  Train {percent_correct(Classesred1, Ttrain):.2f}')\n",
    "\n",
    "Classesred2, _ = reduced_classifier.use(Xtest_reduced)\n",
    "print(f'% Correct  Test {percent_correct(Classesred2, Ttest):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.I have done 4 experiments , 1 & 2 on original data ,3 & 4 on reduced data respectively with same network parameters and network structures.\n",
    "For the network structure epochs=2000,learning rate=0.001 and hiddenlayers=[200,200] I have achieved 100% Training accuracy on original data and 99.82% Training accuracy on reduced data.For the test data i have achoeved 97.88% on original data and 97.73% on test data. so original data worked slightly better than the reduced dimensional data in terms of accuracy.I have experimented on various other parameters. In Experiments 3&4, So to increase the test data accuracy in both types of networks, i have increased the number of epochs to 6000 and reduced the learning rate to 0.0001 and increased the hidden layers of the network to[200,200,200].The training time for this network greatly increased but the training accuracy is 100% in original data  and increased to 99.92% on reduced data. One of the surprising result is reduced data trained network(98.18%) performed better than the original data trained(97.97).It may be surprising that original data triained network performed  slightly less for one time use of the test data ,the key insight is rmse error becomes 0 for original one well after 60% of the epochs completion not incase for reduced data.I have several other experiments like increasing number of epochs to 10000 and training the reduced model to get 100% correct on reduced training set but it doesnt increase the accuracy more than 98% on test data for reduced network(less accuracy than 6000 epochs).I can infer that due to repetitive training with very high number of epochs(10000) and slow learning rate and complex structure the model like on experiment 4 .reduced data is trying matching original data in terms of accurate but for small networks reduced data is far less accurate than orginal data.On this experiment 1 & 3 are optimal parameters to get a matching on the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
